hydra:
  run:
    dir: ${oc.env:PROJECT_ROOT}/hydra/regression/${now:%Y-%m-%d}/${now:%H-%M-%S}

trainer:
  max_epochs: 10000
  gpus: 0

model:
  _target_: pl_modules.modules.in_context.InContextWrap
  graph_pooling_fn: null
  encoder:
    _target_: pl_modules.modules.mlp.MLP
    input_channels: 1
    hidden_channels: 8
    output_channels: 8
    activation_fn: silu
  decoder:
    _target_: transformers.GPT2Model
    config:
      _target_: transformers.GPT2Config
      n_positions: 32
      n_embd: 8
      n_layer: 2
      n_head: 4
      resid_pdrop: 0.0
      embd_pdrop: 0.0
      attn_pdrop: 0.0
      use_cache: False
  label_readout:
    _target_: torch.nn.Linear
    in_features: 8
    out_features: 1
  optimizer_cfg:
    lr: 2e-5
    step_size: 1000
    gamma: 0.5

datamodule:
  _target_: pl_modules.data.dime_in_context.DimeNetDataModule
  mode: no_context       # OR separate OR context OR no_context
  train_csv: ${oc.env:PROJECT_ROOT}/data/strain/db.csv
  test_csv: ${oc.env:PROJECT_ROOT}/data/strain/db.csv
  elements: ${oc.env:PROJECT_ROOT}/data/strain/elements.json
  separate_test: False
  batch_size: 16
  label_scaler:
    _target_: sklearn.preprocessing.StandardScaler
