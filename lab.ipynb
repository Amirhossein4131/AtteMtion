{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch.nn.functional import relu\n",
    "\n",
    "from pymatgen.io.cif import CifParser\n",
    "from pymatgen.analysis.local_env import CrystalNN\n",
    "from pymatgen.core import Structure, Lattice, Site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\n",
    "    \"Mo\": \"./data/Mo\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gvector (gvector):\n",
    "    with open(gvector, \"rb\") as binary_file:\n",
    "                bin_version = int.from_bytes(binary_file.read(4),\n",
    "                                             byteorder='little',\n",
    "                                             signed=False)\n",
    "                if bin_version != 0:\n",
    "                    print(\"Version not supported!\")\n",
    "                    exit(1)\n",
    "                # converting to int to avoid handling little/big endian\n",
    "                flags = int.from_bytes(binary_file.read(2),\n",
    "                                       byteorder='little',\n",
    "                                       signed=False)\n",
    "                n_atoms = int.from_bytes(binary_file.read(4),\n",
    "                                         byteorder='little',\n",
    "                                         signed=False)\n",
    "                g_size = int.from_bytes(binary_file.read(4),\n",
    "                                        byteorder='little',\n",
    "                                        signed=False)\n",
    "                payload = binary_file.read()\n",
    "                data = np.frombuffer(payload, dtype='<f4')\n",
    "                en = data[0]\n",
    "                gvect_size = n_atoms * g_size\n",
    "                spec_tensor = np.reshape((data[1:1+n_atoms]).astype(np.int32),\n",
    "                                     [1, n_atoms])\n",
    "                gvect_tensor = np.reshape(data[1+n_atoms:1+n_atoms+gvect_size],\n",
    "                                      [n_atoms, g_size])\n",
    "    return (gvect_tensor)\n",
    "\n",
    "\n",
    "def json_to_pmg_structure(db_name, json_file):\n",
    "    \"\"\"\n",
    "    converts json files into cif format files\n",
    "    \"\"\"\n",
    "    cif_path = os.path.join(DATASETS[db_name], \n",
    "                            \"train_gv\", \"cifs\")  \n",
    "    \n",
    "    json_path = os.path.join(DATASETS[db_name], \n",
    "                            \"train_gv\", \"jsons\", json_file) \n",
    "    \n",
    "    Path(cif_path).mkdir(parents=True,\n",
    "                          exist_ok=True)\n",
    "    \n",
    "    json_data = read_json(json_path)\n",
    "    lattice_vectors = json_data[\"lattice_vectors\"]\n",
    "    lattice = Lattice(lattice_vectors)\n",
    "\n",
    "    sites = [\n",
    "        Site(species=atom[1], coords=atom[2], properties={\"occupancy\": 1.0})\n",
    "        for atom in json_data[\"atoms\"]\n",
    "    ]\n",
    "\n",
    "    cif_name = json_file.split(\".\")[0] + \".cif\"\n",
    "    structure = Structure(lattice=lattice, species=[\"Mo\"] * len(sites), coords=[site.coords for site in sites])\n",
    "\n",
    "    if os.path.isfile(cif_path + \"/\" + cif_name):\n",
    "        pass\n",
    "    else:\n",
    "        structure.to(filename=cif_path + \"/\" + cif_name)\n",
    "    return structure\n",
    "\n",
    "\n",
    "def get_edge_indexes(structure):\n",
    "    bonded_structure = CrystalNN(weighted_cn=True, distance_cutoffs=(10,  20.))\n",
    "    bonded_structure = bonded_structure.get_bonded_structure(structure)\n",
    "    bonded_structure = bonded_structure.as_dict()\n",
    "    structure_graph = bonded_structure[\"graphs\"][\"adjacency\"]\n",
    "\n",
    "    # len(graph) = number of atoms\n",
    "    edge_index_from = []\n",
    "    edge_index_to = []\n",
    "    edges = []\n",
    "    for i in range (len(structure_graph)):\n",
    "        #iterates over the connected atoms of each atom in the cell\n",
    "        for j in range(len(structure_graph[i])):\n",
    "            edge_index_from.append(i)\n",
    "            edge_id = structure_graph[i][j][\"id\"]\n",
    "            edge_index_to.append(edge_id)\n",
    "            edge = torch.tensor(structure_graph[i][j][\"to_jimage\"])\n",
    "            edges.append(edge)\n",
    "\n",
    "    edge_index_from = torch.tensor(edge_index_from)\n",
    "    edge_index_to = torch.tensor(edge_index_to)\n",
    "\n",
    "    edge_indexes = np.array([edge_index_from, edge_index_to])\n",
    "    edge_indexes = torch.from_numpy(edge_indexes)\n",
    "\n",
    "    edges = np.array(edges)\n",
    "    edges = torch.from_numpy(edges)\n",
    "    return edge_indexes, edges\n",
    "\n",
    "\n",
    "def read_json(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_db_keys(db_name):\n",
    "    db_path = os.path.join(DATASETS[db_name], \"train_gv\", \"gvectors\")\n",
    "    keys = [f.split(\".\")[0] for f in os.listdir(db_path) if os.path.isfile(os.path.join(db_path, f))]\n",
    "\n",
    "    gvector_keys = []\n",
    "    json_keys = []\n",
    "    for item in keys:\n",
    "        gvector_keys.append(item+\".bin\")\n",
    "        json_keys.append(item+\".example\")\n",
    "                  \n",
    "    return gvector_keys, json_keys\n",
    "\n",
    "def get_labels():\n",
    "     \"\"\"gets labels (energy, force, ...)\"\"\"\n",
    "     label_1 = np.random.uniform(1, 2, size=3965)\n",
    "     label_2 = np.random.rand(3965, 3)\n",
    "     label_1 = torch.tensor(label_1, dtype=torch.float)\n",
    "     label_2 = torch.tensor(label_2, dtype=torch.float)\n",
    "     return label_1, label_2\n",
    "\n",
    "\n",
    "\n",
    "def dataset(db_name):\n",
    "    # Parinello vectors\n",
    "    db_path =  os.path.join(DATASETS[db_name], \"train_gv\", \"gvectors\")\n",
    "    gvect_keys, json_keys = get_db_keys(db_name)\n",
    "    set = []\n",
    "    for item in gvect_keys[0:100]:\n",
    "        a = gvector (db_path + \"/\" + item)\n",
    "        a = torch.tensor(a)\n",
    "        set.append(a)\n",
    "    parinello = set\n",
    "\n",
    "    # edge indexes\n",
    "    edge_indexes = []\n",
    "    edges = []\n",
    "\n",
    "    for item in tqdm(json_keys[0:100]):\n",
    "        structure = json_to_pmg_structure(db_name=\"Mo\", json_file=item)\n",
    "        ei, e = get_edge_indexes(structure)\n",
    "        edge_indexes.append(ei)\n",
    "        edges.append(e)\n",
    "         \n",
    "    return parinello, edge_indexes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:18<02:15,  1.54s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m parinello, edge_indexes, edges \u001b[39m=\u001b[39m dataset(db_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mMo\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[101], line 137\u001b[0m, in \u001b[0;36mdataset\u001b[0;34m(db_name)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m tqdm(json_keys[\u001b[39m0\u001b[39m:\u001b[39m100\u001b[39m]):\n\u001b[1;32m    136\u001b[0m     structure \u001b[39m=\u001b[39m json_to_pmg_structure(db_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMo\u001b[39m\u001b[39m\"\u001b[39m, json_file\u001b[39m=\u001b[39mitem)\n\u001b[0;32m--> 137\u001b[0m     ei, e \u001b[39m=\u001b[39m get_edge_indexes(structure)\n\u001b[1;32m    138\u001b[0m     edge_indexes\u001b[39m.\u001b[39mappend(ei)\n\u001b[1;32m    139\u001b[0m     edges\u001b[39m.\u001b[39mappend(e)\n",
      "Cell \u001b[0;32mIn[101], line 64\u001b[0m, in \u001b[0;36mget_edge_indexes\u001b[0;34m(structure)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_edge_indexes\u001b[39m(structure):\n\u001b[1;32m     63\u001b[0m     bonded_structure \u001b[39m=\u001b[39m CrystalNN(weighted_cn\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, distance_cutoffs\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,  \u001b[39m20.\u001b[39m))\n\u001b[0;32m---> 64\u001b[0m     bonded_structure \u001b[39m=\u001b[39m bonded_structure\u001b[39m.\u001b[39;49mget_bonded_structure(structure)\n\u001b[1;32m     65\u001b[0m     bonded_structure \u001b[39m=\u001b[39m bonded_structure\u001b[39m.\u001b[39mas_dict()\n\u001b[1;32m     66\u001b[0m     structure_graph \u001b[39m=\u001b[39m bonded_structure[\u001b[39m\"\u001b[39m\u001b[39mgraphs\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39madjacency\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymatgen/analysis/local_env.py:622\u001b[0m, in \u001b[0;36mNearNeighbors.get_bonded_structure\u001b[0;34m(self, structure, decorate, weights, edge_properties, on_disorder)\u001b[0m\n\u001b[1;32m    619\u001b[0m     order_parameters \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_order_parameters(structure, n) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(structure))]\n\u001b[1;32m    620\u001b[0m     structure\u001b[39m.\u001b[39madd_site_property(\u001b[39m\"\u001b[39m\u001b[39morder_parameters\u001b[39m\u001b[39m\"\u001b[39m, order_parameters)\n\u001b[0;32m--> 622\u001b[0m sg \u001b[39m=\u001b[39m StructureGraph\u001b[39m.\u001b[39;49mwith_local_env_strategy(structure, \u001b[39mself\u001b[39;49m, weights\u001b[39m=\u001b[39;49mweights, edge_properties\u001b[39m=\u001b[39;49medge_properties)\n\u001b[1;32m    624\u001b[0m \u001b[39m# sets the attributes\u001b[39;00m\n\u001b[1;32m    625\u001b[0m sg\u001b[39m.\u001b[39mset_node_attributes()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymatgen/analysis/graphs.py:260\u001b[0m, in \u001b[0;36mStructureGraph.with_local_env_strategy\u001b[0;34m(structure, strategy, weights, edge_properties)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mChosen strategy is not designed for use with structures! Please choose another strategy.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    258\u001b[0m sg \u001b[39m=\u001b[39m StructureGraph\u001b[39m.\u001b[39mwith_empty_graph(structure, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbonds\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 260\u001b[0m \u001b[39mfor\u001b[39;00m idx, neighbors \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(strategy\u001b[39m.\u001b[39;49mget_all_nn_info(structure)):\n\u001b[1;32m    261\u001b[0m     \u001b[39mfor\u001b[39;00m neighbor \u001b[39min\u001b[39;00m neighbors:\n\u001b[1;32m    262\u001b[0m         \u001b[39m# local_env will always try to add two edges\u001b[39;00m\n\u001b[1;32m    263\u001b[0m         \u001b[39m# for any one bond, one from site u to site v\u001b[39;00m\n\u001b[1;32m    264\u001b[0m         \u001b[39m# and another form site v to site u: this is\u001b[39;00m\n\u001b[1;32m    265\u001b[0m         \u001b[39m# harmless, so warn_duplicates=False\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         sg\u001b[39m.\u001b[39madd_edge(\n\u001b[1;32m    267\u001b[0m             from_index\u001b[39m=\u001b[39midx,\n\u001b[1;32m    268\u001b[0m             from_jimage\u001b[39m=\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    273\u001b[0m             warn_duplicates\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymatgen/analysis/local_env.py:416\u001b[0m, in \u001b[0;36mNearNeighbors.get_all_nn_info\u001b[0;34m(self, structure)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_all_nn_info\u001b[39m(\u001b[39mself\u001b[39m, structure: Structure):\n\u001b[1;32m    408\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a listing of all neighbors for all sites in a structure.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \n\u001b[1;32m    410\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39m            entry has the same format as `get_nn_info`\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 416\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_nn_info(structure, n) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(structure))]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymatgen/analysis/local_env.py:416\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_all_nn_info\u001b[39m(\u001b[39mself\u001b[39m, structure: Structure):\n\u001b[1;32m    408\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a listing of all neighbors for all sites in a structure.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \n\u001b[1;32m    410\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[39m            entry has the same format as `get_nn_info`\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 416\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_nn_info(structure, n) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(structure))]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymatgen/analysis/local_env.py:3855\u001b[0m, in \u001b[0;36mCrystalNN.get_nn_info\u001b[0;34m(self, structure, n)\u001b[0m\n\u001b[1;32m   3853\u001b[0m \u001b[39mfor\u001b[39;00m cn \u001b[39min\u001b[39;00m nn_data\u001b[39m.\u001b[39mcn_nninfo:\n\u001b[1;32m   3854\u001b[0m     \u001b[39mfor\u001b[39;00m cn_entry \u001b[39min\u001b[39;00m nn_data\u001b[39m.\u001b[39mcn_nninfo[cn]:\n\u001b[0;32m-> 3855\u001b[0m         \u001b[39mif\u001b[39;00m entry[\u001b[39m\"\u001b[39;49m\u001b[39msite\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m==\u001b[39;49m cn_entry[\u001b[39m\"\u001b[39;49m\u001b[39msite\u001b[39;49m\u001b[39m\"\u001b[39;49m]:\n\u001b[1;32m   3856\u001b[0m             weight \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m nn_data\u001b[39m.\u001b[39mcn_weights[cn]\n\u001b[1;32m   3858\u001b[0m entry[\u001b[39m\"\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m weight\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pymatgen/core/sites.py:485\u001b[0m, in \u001b[0;36mPeriodicSite.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(other, Site):\n\u001b[1;32m    480\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m    482\u001b[0m \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    483\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspecies \u001b[39m==\u001b[39m other\u001b[39m.\u001b[39mspecies\n\u001b[1;32m    484\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlattice \u001b[39m==\u001b[39m other\u001b[39m.\u001b[39mlattice\n\u001b[0;32m--> 485\u001b[0m     \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39;49mallclose(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoords, other\u001b[39m.\u001b[39;49mcoords, atol\u001b[39m=\u001b[39;49mSite\u001b[39m.\u001b[39;49mposition_atol)\n\u001b[1;32m    486\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproperties \u001b[39m==\u001b[39m other\u001b[39m.\u001b[39mproperties\n\u001b[1;32m    487\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/numeric.py:2241\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2170\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[1;32m   2171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mallclose\u001b[39m(a, b, rtol\u001b[39m=\u001b[39m\u001b[39m1.e-5\u001b[39m, atol\u001b[39m=\u001b[39m\u001b[39m1.e-8\u001b[39m, equal_nan\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   2172\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2173\u001b[0m \u001b[39m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[1;32m   2174\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2239\u001b[0m \n\u001b[1;32m   2240\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2241\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m(isclose(a, b, rtol\u001b[39m=\u001b[39;49mrtol, atol\u001b[39m=\u001b[39;49matol, equal_nan\u001b[39m=\u001b[39;49mequal_nan))\n\u001b[1;32m   2242\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(res)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/numeric.py:2345\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[39m# Make sure y is an inexact type to avoid bad behavior on abs(MIN_INT).\u001b[39;00m\n\u001b[1;32m   2338\u001b[0m \u001b[39m# This will cause casting of x later. Also, make sure to allow subclasses\u001b[39;00m\n\u001b[1;32m   2339\u001b[0m \u001b[39m# (e.g., for numpy.ma).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2342\u001b[0m \u001b[39m#       timedelta works if `atol` is an integer or also a timedelta.\u001b[39;00m\n\u001b[1;32m   2343\u001b[0m \u001b[39m#       Although, the default tolerances are unlikely to be useful\u001b[39;00m\n\u001b[1;32m   2344\u001b[0m \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mm\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 2345\u001b[0m     dt \u001b[39m=\u001b[39m multiarray\u001b[39m.\u001b[39;49mresult_type(y, \u001b[39m1.\u001b[39;49m)\n\u001b[1;32m   2346\u001b[0m     y \u001b[39m=\u001b[39m asanyarray(y, dtype\u001b[39m=\u001b[39mdt)\n\u001b[1;32m   2348\u001b[0m xfin \u001b[39m=\u001b[39m isfinite(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "parinello, edge_indexes, edges = dataset(db_name=\"Mo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3965])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_1, label_2 = get_labels()\n",
    "label_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(db_name, batch_size):\n",
    "    \"\"\"Create a PyTorch Geometric Data object\"\"\"\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    parinello, edge_indexes, edges = dataset(db_name=db_name)\n",
    "\n",
    "    label_1, label_2 = get_labels()\n",
    "\n",
    "    dataset = []\n",
    "    for i in range (len(parinello)):\n",
    "        data = Data(x=parinello[i], edge_index=edge_indexes[i], to_j=edges[i], y=label_1[i])\n",
    "        dataset.append(data)\n",
    "\n",
    "    # Create a PyTorch Geometric DataLoader\n",
    "    batch_size = batch_size\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i in range (len(parinello)):\n",
    "    data = Data(x=parinello[i], edge_index=edge_indexes[i], to_j=edges[i], y=label_1[i])\n",
    "    #data = Data(x=edges[i],edge_index=edge_indexes[i], y=label_1[i])\n",
    "    dataset.append(data)\n",
    "\n",
    "# Create a PyTorch Geometric DataLoader\n",
    "batch_size = 20\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(x=[137, 160], edge_index=[2, 965], y=[20], to_j=[965, 3], batch=[137], ptr=[21])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(data_loader))\n",
    "\n",
    "batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch.nn import Module, MultiheadAttention, Linear, SiLU\n",
    "from torch_geometric.nn import global_mean_pool, GATConv\n",
    "from torch import sigmoid\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiceMultiheadAttention(Module):\n",
    " \n",
    "    def __init__(self, in_channels, out_channels, heads):\n",
    "        super(NiceMultiheadAttention, self).__init__()\n",
    "        self.lin_k = Linear(in_channels, out_channels)\n",
    "        self.lin_q = Linear(in_channels, out_channels)\n",
    "        self.lin_v = Linear(in_channels, out_channels)\n",
    "        self.att = MultiheadAttention(out_channels, heads, batch_first=True)\n",
    "    \n",
    "    def forward(self, h):\n",
    "        K = self.lin_k(h)\n",
    "        Q = self.lin_q(h)\n",
    "        V = self.lin_v(h)\n",
    "        out, weights = self.att(K[:, None, :], Q[:, None, :], V[:, None, :])\n",
    "        return out, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_h1 torch.Size([137, 32])\n",
      "graph_h1 after relu torch.Size([137, 32])\n",
      "graph_h2 torch.Size([137, 64])\n",
      "graph_h2 after relu torch.Size([137, 64])\n",
      "graph_h torch.Size([20, 64])\n",
      "graph_h after relu torch.Size([20, 64])\n",
      "h1 torch.Size([20, 1, 8])\n",
      "h1 torch.Size([20, 1, 8])\n",
      "output shape tensor([[[-0.2471]],\n",
      "\n",
      "        [[-0.3141]],\n",
      "\n",
      "        [[-0.3380]],\n",
      "\n",
      "        [[-0.2980]],\n",
      "\n",
      "        [[-0.1914]],\n",
      "\n",
      "        [[-0.3074]],\n",
      "\n",
      "        [[-0.1482]],\n",
      "\n",
      "        [[-0.1892]],\n",
      "\n",
      "        [[-0.3200]],\n",
      "\n",
      "        [[-0.0338]],\n",
      "\n",
      "        [[-0.2799]],\n",
      "\n",
      "        [[-0.2958]],\n",
      "\n",
      "        [[ 0.2085]],\n",
      "\n",
      "        [[-0.2499]],\n",
      "\n",
      "        [[-0.1234]],\n",
      "\n",
      "        [[-0.3226]],\n",
      "\n",
      "        [[-0.2652]],\n",
      "\n",
      "        [[-0.2545]],\n",
      "\n",
      "        [[-0.2876]],\n",
      "\n",
      "        [[-0.3337]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "graph1 = GATConv(in_channels=160, out_channels=16, heads=2)\n",
    "graph2 = GATConv(in_channels=32, out_channels=8, heads=8)\n",
    "att1 = NiceMultiheadAttention(64, 8, 2)\n",
    "\n",
    "readout = Linear(8, 1)\n",
    "\n",
    "graph_h1 = graph1(batch.x, batch.edge_index)\n",
    "print(\"graph_h1\", graph_h1.shape)\n",
    "\n",
    "graph_h1 = relu(graph_h1)\n",
    "print(\"graph_h1 after relu\", graph_h1.shape)\n",
    "\n",
    "graph_h2 = graph2(graph_h1, batch.edge_index)\n",
    "print(\"graph_h2\", graph_h2.shape)\n",
    "\n",
    "graph_h2 = relu(graph_h2)\n",
    "print(\"graph_h2 after relu\", graph_h2.shape)\n",
    "\n",
    "graph_h = global_mean_pool(graph_h2, batch.batch)\n",
    "print(\"graph_h\", graph_h.shape)\n",
    "\n",
    "graph_h = relu(graph_h)\n",
    "print(\"graph_h after relu\", graph_h.shape)\n",
    "\n",
    "h1 = att1(graph_h)\n",
    "print(\"h1\", h1[0].shape)\n",
    "h1 = relu(h1[0])\n",
    "print(\"h1\", h1.shape)\n",
    "\n",
    "o = readout(h1[0:])\n",
    "\n",
    "print(\"output shape\" , o)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'to_jimage': (0, 0, 1), 'weight': 1.0, 'id': 0, 'key': 0},\n",
       "  {'to_jimage': (0, 1, -1), 'weight': 0.9803019331352788, 'id': 0, 'key': 1},\n",
       "  {'to_jimage': (1, 0, -1), 'weight': 0.8333345006247604, 'id': 0, 'key': 2},\n",
       "  {'to_jimage': (1, 1, -1), 'weight': 0.654636307722224, 'id': 0, 'key': 3},\n",
       "  {'to_jimage': (0, 1, 0), 'weight': 0.4280000036374567, 'id': 0, 'key': 4},\n",
       "  {'to_jimage': (1, 0, 0), 'weight': 0.3979587118849426, 'id': 0, 'key': 5},\n",
       "  {'to_jimage': (1, 1, -2), 'weight': 0.19152603496472706, 'id': 0, 'key': 6}]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structure = json_to_pmg_structure(db_name=\"Mo\", json_file=\"1111.example\")\n",
    "\n",
    "\n",
    "bonded_structure = CrystalNN(weighted_cn=True, distance_cutoffs=(10,  20.))\n",
    "bonded_structure = bonded_structure.get_bonded_structure(structure)\n",
    "bonded_structure = bonded_structure.as_dict()\n",
    "structure_graph = bonded_structure[\"graphs\"][\"adjacency\"]\n",
    "\n",
    "#bonded_structure\n",
    "#len(structure_graph)\n",
    "structure_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch.nn import Module, MultiheadAttention, Linear\n",
    "from torch_geometric.nn import global_mean_pool, GATConv\n",
    "from torch import sigmoid\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import random_split\n",
    "from torchmetrics import Accuracy\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = []\n",
    "for i in range (len(parinello[0:90])):\n",
    "    data = Data(x=parinello[i], edge_index=edge_indexes[i], to_j=edges[i], y=label_1[i])\n",
    "    train_dataset.append(data)\n",
    "\n",
    "# Create a PyTorch Geometric DataLoader\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = []\n",
    "for i in range (len(parinello[90:])):\n",
    "    data = Data(x=parinello[i], edge_index=edge_indexes[i], to_j=edges[i], y=label_1[i])\n",
    "    test_dataset.append(data)\n",
    "\n",
    "# Create a PyTorch Geometric DataLoader\n",
    "batch_size = 1\n",
    "val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name    | Type                   | Params\n",
      "---------------------------------------------------\n",
      "0 | graph1  | GATConv                | 83.5 K\n",
      "1 | graph2  | GATConv                | 263 K \n",
      "2 | att1    | NiceMultiheadAttention | 1.8 M \n",
      "3 | att2    | NiceMultiheadAttention | 1.8 M \n",
      "4 | readout | Linear                 | 513   \n",
      "---------------------------------------------------\n",
      "4.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 M     Total params\n",
      "16.099    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e94fdf0a4624d528dfb3b35203a0af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e76074a9d3549e1b853b628b36a3482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed0b8df9eed429c9e5cafe512054cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8567850bd5cf4b6ea28434d4031cb243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3b9b5e258949f9addaa91d7deebd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42279b9b69bb45cba5928f9eb6b1a39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5f898031974004b531e4bdd1854bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "class InContextGNN(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(InContextGNN, self).__init__()\n",
    "\n",
    "        self.graph1 = GATConv(in_channels=160, out_channels=64, heads=8)\n",
    "        self.graph2 = GATConv(in_channels=512, out_channels=64, heads=8)\n",
    "        self.att1 = NiceMultiheadAttention(512, 512, 8)\n",
    "        self.att2 = NiceMultiheadAttention(512, 512, 8)\n",
    "        self.act = torch.sigmoid\n",
    "        self.readout = Linear(512, 1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        graph_h1 = self.graph1(batch.x, batch.edge_index)\n",
    "        graph_h1 = self.act(graph_h1)\n",
    "        graph_h2 = self.graph2(graph_h1, batch.edge_index)\n",
    "        graph_h2 = self.act(graph_h2)\n",
    "        graph_h = global_mean_pool(graph_h2, batch.batch)\n",
    "        graph_h = self.act(graph_h)\n",
    "        h1, h1_weights = self.att1(graph_h)\n",
    "        h1 = self.act(h1)\n",
    "        h2 = self.att2(h1)\n",
    "        h2 = self.act(h2[0])\n",
    "        out = self.readout(h2)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        output = self(batch)\n",
    "        loss = torch.nn.functional.mse_loss(output, batch.y.view(-1, 1))\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        output = self(batch)\n",
    "        loss = torch.nn.functional.mse_loss(output, batch.y.view(-1, 1))\n",
    "        self.log('val_loss', loss)\n",
    "        return {'val_loss': loss}\n",
    "\n",
    "model = InContextGNN()\n",
    "tensorboard_logger = TensorBoardLogger(\"logs\", name=\"your_experiment_name\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=5,\n",
    "    logger=tensorboard_logger,\n",
    "    log_every_n_steps=1,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2349.97s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "2023-11-14 16:44:18.677096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-11-14 16:44:18.677120: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amirhossein/miniconda3/lib/python3.10/site-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/home/amirhossein/miniconda3/lib/python3.10/site-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/amirhossein/miniconda3/bin/tensorboard\", line 8, in <module>\n",
      "    sys.exit(run_main())\n",
      "  File \"/home/amirhossein/miniconda3/lib/python3.10/site-packages/tensorboard/main.py\", line 39, in run_main\n",
      "    main_lib.global_init()\n",
      "  File \"/home/amirhossein/miniconda3/lib/python3.10/site-packages/tensorboard/main_lib.py\", line 40, in global_init\n",
      "    if getattr(tf, \"__version__\", \"stub\") == \"stub\":\n",
      "  File \"/home/amirhossein/miniconda3/lib/python3.10/site-packages/tensorboard/lazy.py\", line 65, in __getattr__\n",
      "    return getattr(load_once(self), attr_name)\n",
      "  File \"/home/amirhossein/miniconda3/lib/python3.10/site-packages/tensorboard/lazy.py\", line 97, in wrapper\n",
      "    cache[arg] = f(arg)\n",
      "  File \"/home/amirhossein/miniconda3/lib/python3.10/site-packages/tensorboard/lazy.py\", line 50, in load_once\n",
      "    module = load_fn()\n",
      "  File \"/home/amirhossein/miniconda3/lib/python3.10/site-packages/tensorboard/compat/__init__.py\", line 45, in tf\n",
      "    import tensorflow\n",
      "  File \"/home/amirhossein/miniconda3/lib/python3.10/site-packages/tensorflow/__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"/home/amirhossein/miniconda3/lib/python3.10/site-packages/tensorflow/python/__init__.py\", line 36, in <module>\n",
      "    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\n",
      "  File \"/home/amirhossein/miniconda3/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 60, in <module>\n",
      "    from tensorflow.python._pywrap_tensorflow_internal import *\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir \"logs/your_experiment_name/version_2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(db_name):\n",
    "     \"\"\"gets labels (energy, force, ...)\"\"\"\n",
    "     \n",
    "     label = []\n",
    "     db_path =  os.path.join(DATASETS[db_name], \"train_gv\", \"jsons\")\n",
    "     gvect_keys, json_keys = get_db_keys(db_name)\n",
    "     \n",
    "     for item in json_keys:\n",
    "          example = os.path.join(db_path, item)\n",
    "          \n",
    "          with open (example, \"r\") as file:\n",
    "               data = json.load(file)\n",
    "          \n",
    "          label.append(data[\"energy\"][0])\n",
    "     \n",
    "     label = torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "     return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data(db_name, batch_size):\n",
    "    \"\"\"Create a PyTorch Geometric Data object\"\"\"\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    parinello, edge_indexes, edges = dataset(db_name=db_name)\n",
    "\n",
    "    labels = get_labels(db_name)\n",
    "\n",
    "    db = []\n",
    "    for i in range (len(parinello)):\n",
    "        data = Data(x=parinello[i], edge_index=edge_indexes[i], to_j=edges[i], y=labels[i])\n",
    "        db.append(data)\n",
    "\n",
    "    # Create a PyTorch Geometric DataLoader\n",
    "    batch_size = batch_size\n",
    "    dataset_size = len(db)\n",
    "    train_size = int(0.8 * dataset_size)\n",
    "    val_size = dataset_size - train_size\n",
    "    train_dataset, val_dataset = random_split(db, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:59<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = data(\"Mo\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
